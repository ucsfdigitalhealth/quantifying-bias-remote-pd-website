# Quantifying Device Type and Handedness Biases in a Remote Parkinson's Disease AI-Powered Assessment

This project investigates algorithmic fairness in AI models for detecting Parkinsonâ€™s Disease based on interaction data collected through a remote assessment platform. It includes stages for data generation, model training, testing, and bias evaluation across demographic factors such as race, sex, device type, and dominant hand.

---

## ğŸ“ Project Structure

```
quantifying-bias-remote-pd-website
   â”œâ”€â”€ analysis/                  # Output plots and figures
   â”œâ”€â”€ data/                      # Raw, Intermediate and Processed datasets
   â”œâ”€â”€ src/                       # Source code for models, fairness, and utilities
   â”œâ”€â”€ weights/                   # Saved model weights
   â”œâ”€â”€ config.py                  # Project configuration
   â”œâ”€â”€ main.py                    # Main CLI script
   â”œâ”€â”€ Part 1 - Data Preparation.ipynb
   â”œâ”€â”€ Part 2 - Training and Testing the AI Model.ipynb
   â”œâ”€â”€ Part 3 - Quantify Bias After Race Upsample.ipynb
   â”œâ”€â”€ Part 3 - Quantify Bias Before Race Upsample.ipynb
   â”œâ”€â”€ requirements.txt
```

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repository**

   ```bash
   git clone https://github.com/zerinnasrintumpa/quantifying-bias-remote-pd-website.git
   cd quantifying-bias-remote-pd-website
   ```

2. **Create and activate a virtual environment**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸš€ How to Run the Project

All major actions can be run using the CLI interface via `main.py`:

### ğŸ“Š Generate Data

```bash
python main.py --generate-data
```

### ğŸ¤– Train Models

```bash
python main.py --train-model
```

### ğŸ§ª Test on Held-out Set

```bash
python main.py --test-model
```

### âš–ï¸ Evaluate Fairness

```bash
# Without race upsampling
python main.py --evaluate-model-bias race_upsample_false

# With race upsampling
python main.py --evaluate-model-bias race_upsample_true
```

---

## ğŸ““ Notebooks

- `Part 1`: Extract and preprocess features
- `Part 2`: Train and evaluate ML models
- `Part 3`: Analyze fairness before and after race upsampling

---

## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
